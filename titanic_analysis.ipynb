{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction\n",
    "\n",
    "A comprehensive machine learning solution for predicting Titanic passenger survival.\n",
    "\n",
    "This notebook covers:\n",
    "1. Data cleaning and preprocessing\n",
    "2. Feature engineering\n",
    "3. Exploratory data analysis (EDA)\n",
    "4. Machine learning model building\n",
    "5. Prediction and submission\n",
    "\n",
    "Tools used: Python, Pandas, NumPy, Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load the Titanic datasets: train.csv, test.csv, and gender_submission.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load and return the Titanic datasets.\"\"\"\n",
    "    print(\"Loading datasets...\")\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    gender_submission = pd.read_csv('gender_submission.csv')\n",
    "    \n",
    "    print(f\"Training data shape: {train_df.shape}\")\n",
    "    print(f\"Test data shape: {test_df.shape}\")\n",
    "    print(f\"Sample submission shape: {gender_submission.shape}\")\n",
    "    \n",
    "    return train_df, test_df, gender_submission\n",
    "\n",
    "# Load data\n",
    "train_df, test_df, gender_submission = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing\n",
    "\n",
    "Handle missing values, convert categorical variables, and prepare data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(train_df, test_df):\n",
    "    \"\"\"Clean and preprocess the data.\"\"\"\n",
    "    print(\"\\n=== DATA CLEANING ===\")\n",
    "    \n",
    "    # Create copies\n",
    "    train_clean = train_df.copy()\n",
    "    test_clean = test_df.copy()\n",
    "    \n",
    "    # Handle missing values - Age\n",
    "    print(\"Filling missing Age values...\")\n",
    "    train_clean['Age'] = train_clean.groupby(['Pclass', 'Sex'])['Age'].transform(\n",
    "        lambda x: x.fillna(x.median()))\n",
    "    test_clean['Age'] = test_clean.groupby(['Pclass', 'Sex'])['Age'].transform(\n",
    "        lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    # Handle missing values - Embarked\n",
    "    print(\"Filling missing Embarked values...\")\n",
    "    train_clean['Embarked'] = train_clean['Embarked'].fillna('S')\n",
    "    \n",
    "    # Handle missing values - Fare\n",
    "    print(\"Filling missing Fare values...\")\n",
    "    test_clean['Fare'] = test_clean['Fare'].fillna(test_clean['Fare'].median())\n",
    "    \n",
    "    # Convert categorical variables\n",
    "    print(\"Converting categorical variables...\")\n",
    "    train_clean['Sex'] = train_clean['Sex'].map({'male': 0, 'female': 1})\n",
    "    test_clean['Sex'] = test_clean['Sex'].map({'male': 0, 'female': 1})\n",
    "    \n",
    "    # One-hot encode Embarked\n",
    "    train_clean = pd.get_dummies(train_clean, columns=['Embarked'], prefix='Embarked')\n",
    "    test_clean = pd.get_dummies(test_clean, columns=['Embarked'], prefix='Embarked')\n",
    "    \n",
    "    print(\"Data cleaning completed!\")\n",
    "    return train_clean, test_clean\n",
    "\n",
    "# Clean data\n",
    "train_clean, test_clean = data_cleaning(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Create new features from existing data to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(train_clean, test_clean):\n",
    "    \"\"\"Create new features from existing data.\"\"\"\n",
    "    print(\"\\n=== FEATURE ENGINEERING ===\")\n",
    "    \n",
    "    # Create family size feature\n",
    "    print(\"Creating family size feature...\")\n",
    "    train_clean['FamilySize'] = train_clean['SibSp'] + train_clean['Parch'] + 1\n",
    "    test_clean['FamilySize'] = test_clean['SibSp'] + test_clean['Parch'] + 1\n",
    "    \n",
    "    # Create is alone feature\n",
    "    print(\"Creating is alone feature...\")\n",
    "    train_clean['IsAlone'] = (train_clean['FamilySize'] == 1).astype(int)\n",
    "    test_clean['IsAlone'] = (test_clean['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # Extract titles from names\n",
    "    print(\"Extracting titles from names...\")\n",
    "    def extract_title(name):\n",
    "        return name.split(', ')[1].split('.')[0]\n",
    "    \n",
    "    train_clean['Title'] = train_clean['Name'].apply(extract_title)\n",
    "    test_clean['Title'] = test_clean['Name'].apply(extract_title)\n",
    "    \n",
    "    # Group rare titles\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "        'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare',\n",
    "        'Mlle': 'Miss', 'Countess': 'Rare', 'Ms': 'Miss', 'Lady': 'Rare',\n",
    "        'Jonkheer': 'Rare', 'Don': 'Rare', 'Dona': 'Rare', 'Mme': 'Mrs',\n",
    "        'Capt': 'Rare', 'Sir': 'Rare'\n",
    "    }\n",
    "    \n",
    "    train_clean['Title'] = train_clean['Title'].map(title_mapping)\n",
    "    test_clean['Title'] = test_clean['Title'].map(title_mapping)\n",
    "    \n",
    "    # One-hot encode titles\n",
    "    train_clean = pd.get_dummies(train_clean, columns=['Title'], prefix='Title')\n",
    "    test_clean = pd.get_dummies(test_clean, columns=['Title'], prefix='Title')\n",
    "    \n",
    "    # Create age bins\n",
    "    print(\"Creating age bins...\")\n",
    "    train_clean['AgeBin'] = pd.cut(train_clean['Age'], bins=[0, 12, 18, 35, 60, 100], \n",
    "                                  labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n",
    "    test_clean['AgeBin'] = pd.cut(test_clean['Age'], bins=[0, 12, 18, 35, 60, 100], \n",
    "                                 labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n",
    "    \n",
    "    # One-hot encode age bins\n",
    "    train_clean = pd.get_dummies(train_clean, columns=['AgeBin'], prefix='Age')\n",
    "    test_clean = pd.get_dummies(test_clean, columns=['AgeBin'], prefix='Age')\n",
    "    \n",
    "    print(\"Feature engineering completed!\")\n",
    "    return train_clean, test_clean\n",
    "\n",
    "# Feature engineering\n",
    "train_clean, test_clean = feature_engineering(train_clean, test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "Analyze the data and create visualizations to understand patterns and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploratory_data_analysis(train_clean, train_df):\n",
    "    \"\"\"Perform exploratory data analysis and create visualizations.\"\"\"\n",
    "    print(\"\\n=== EXPLORATORY DATA ANALYSIS ===\")\n",
    "    \n",
    "    # Basic survival statistics\n",
    "    survival_rate = train_df['Survived'].mean()\n",
    "    print(f\"Overall survival rate: {survival_rate:.2%}\")\n",
    "    \n",
    "    # Survival by gender\n",
    "    gender_survival = train_df.groupby('Sex')['Survived'].mean()\n",
    "    print(f\"Female survival rate: {gender_survival['female']:.2%}\")\n",
    "    print(f\"Male survival rate: {gender_survival['male']:.2%}\")\n",
    "    \n",
    "    # Survival by passenger class\n",
    "    class_survival = train_df.groupby('Pclass')['Survived'].mean()\n",
    "    print(\"\\nSurvival by class:\")\n",
    "    for pclass, rate in class_survival.items():\n",
    "        print(f\"Class {pclass}: {rate:.2%}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    print(\"\\nCreating visualizations...\")\n",
    "    \n",
    "    # Survival by gender plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x='Sex', y='Survived', data=train_df)\n",
    "    plt.title('Survival Rate by Gender')\n",
    "    plt.xticks([0, 1], ['Male', 'Female'])\n",
    "    plt.ylabel('Survival Rate')\n",
    "    plt.savefig('survival_by_gender.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Survival by class plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x='Pclass', y='Survived', data=train_df)\n",
    "    plt.title('Survival Rate by Passenger Class')\n",
    "    plt.ylabel('Survival Rate')\n",
    "    plt.savefig('survival_by_class.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Age distribution by survival\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=train_df, x='Age', hue='Survived', kde=True, bins=30)\n",
    "    plt.title('Age Distribution by Survival')\n",
    "    plt.savefig('age_distribution.png')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"EDA completed! Visualizations saved as PNG files.\")\n",
    "\n",
    "# EDA\n",
    "exploratory_data_analysis(train_clean, train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "Build and evaluate machine learning models for survival prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models(train_clean):\n",
    "    \"\"\"Build and evaluate machine learning models.\"\"\"\n",
    "    print(\"\\n=== MODEL BUILDING ===\")\n",
    "    \n",
    "    # Prepare features\n",
    "    features_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived']\n",
    "    X = train_clean.drop(features_to_drop, axis=1)\n",
    "    y = train_clean['Survived']\n",
    "    \n",
    "    print(f\"Training features shape: {X.shape}\")\n",
    "    \n",
    "    # Split data for validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "    }\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    results = {}\n",
    "    print(\"\\nModel Performance:\")\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        results[name] = accuracy\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "        \n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Validation Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    \n",
    "    # Return best model and features\n",
    "    best_model_name = max(results, key=results.get)\n",
    "    best_model = models[best_model_name]\n",
    "    best_model.fit(X, y)  # Train on full data\n",
    "    \n",
    "    print(f\"\\nBest model: {best_model_name}\")\n",
    "    return best_model, X\n",
    "\n",
    "# Build models\n",
    "best_model, X = build_models(train_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "Use the best model to make predictions on the test data and create a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, train_clean, test_clean):\n",
    "    \"\"\"Make predictions on test data and create submission.\"\"\"\n",
    "    print(\"\\n=== MAKING PREDICTIONS ===\")\n",
    "    \n",
    "    # Prepare test features (same as training features)\n",
    "    features_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived']\n",
    "    X_train = train_clean.drop(features_to_drop, axis=1)\n",
    "    X_test = test_clean.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "    \n",
    "    # Ensure same columns in test data\n",
    "    missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "    for col in missing_cols:\n",
    "        X_test[col] = 0\n",
    "    X_test = X_test[X_train.columns]\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Create submission file\n",
    "    submission = pd.DataFrame({\n",
    "        'PassengerId': test_clean['PassengerId'],\n",
    "        'Survived': predictions\n",
    "    })\n",
    "    \n",
    "    # Save submission\n",
    "    submission.to_csv('titanic_submission.csv', index=False)\n",
    "    \n",
    "    print(f\"Predictions completed!\")\n",
    "    print(f\"Number of predicted survivors: {submission['Survived'].sum()}/{len(submission)}\")\n",
    "    print(\"Submission file saved as 'titanic_submission.csv'\")\n",
    "    \n",
    "    return submission\n",
    "\n",
    "# Make predictions\n",
    "submission = make_predictions(best_model, train_clean, test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The analysis is complete! The notebook has:\n",
    "- Loaded and cleaned the data\n",
    "- Engineered new features\n",
    "- Performed exploratory data analysis with visualizations\n",
    "- Built and evaluated machine learning models\n",
    "- Made predictions and created a submission file\n",
    "\n",
    "Files created:\n",
    "- titanic_submission.csv (predictions)\n",
    "- survival_by_gender.png (visualization)\n",
    "- survival_by_class.png (visualization)\n",
    "- age_distribution.png (visualization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
